{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with Tensorflow: The Basic, Ugly Way\n",
    "\n",
    "Let's build a multilayer perceptron with Tensorflow that will try to classify handwritten digits from the famous MNSIT dataset. For sure, the model we are about to make will perform only marginally well, but it will suffice as an example. The syntax style we will use to create, train, and evaluate our model is considerably more verbose that what we'll use later, but it's good to get a peek at how the sausage is made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and get the data.\n",
    "\n",
    "This dataset is included with Tensorflow as two numpy arrays -- one for training and the other for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format.\n",
    "\n",
    "The images are stored as arrays of values ranging from `0.0` to `1.0`, which represents the shades of the pixels. The original images were 28 by 28 pixels, but are now represented as flat vectors of 784 elements. It's possible to use matplotlib to visualize the original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e203375eb8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[101].reshape(28, 28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "To start there are three parameters we need to define. Getting the optimals values is a *very* difficult problem and is an area of study unto itself. Doing this step on a dataset that you're not familiar with could be a days-long task. Fortunately, the MNIST dataset is well-trodden ground, so there are some good suggestions out there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 784 and 256 for 'MatMul_1' (op: 'MatMul') with input shapes: [?,784], [256,256].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\ozbon\\appdata\\local\\pypoetry\\cache\\virtualenvs\\udemy-python-for-data-science-py3.6\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1628\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 784 and 256 for 'MatMul_1' (op: 'MatMul') with input shapes: [?,784], [256,256].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-7df41e7b7cd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m     }\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultilayer_perceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-7df41e7b7cd5>\u001b[0m in \u001b[0;36mmultilayer_perceptron\u001b[1;34m(x, weights, biases)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mlayer_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mlayer_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'h2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mlayer_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ozbon\\appdata\\local\\pypoetry\\cache\\virtualenvs\\udemy-python-for-data-science-py3.6\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   2055\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2056\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[1;32m-> 2057\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   2058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ozbon\\appdata\\local\\pypoetry\\cache\\virtualenvs\\udemy-python-for-data-science-py3.6\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   4854\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m   4855\u001b[0m         \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4856\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   4857\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4858\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ozbon\\appdata\\local\\pypoetry\\cache\\virtualenvs\\udemy-python-for-data-science-py3.6\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ozbon\\appdata\\local\\pypoetry\\cache\\virtualenvs\\udemy-python-for-data-science-py3.6\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mc:\\users\\ozbon\\appdata\\local\\pypoetry\\cache\\virtualenvs\\udemy-python-for-data-science-py3.6\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3274\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3276\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ozbon\\appdata\\local\\pypoetry\\cache\\virtualenvs\\udemy-python-for-data-science-py3.6\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1792\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ozbon\\appdata\\local\\pypoetry\\cache\\virtualenvs\\udemy-python-for-data-science-py3.6\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 784 and 256 for 'MatMul_1' (op: 'MatMul') with input shapes: [?,784], [256,256]."
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001 # Default 0.001\n",
    "training_epochs = 15 # Default 15\n",
    "batch_size = 100 # Default 100\n",
    "\n",
    "n_hidden_1 = 256 # Default 256\n",
    "n_hidden_2 = 256 # Default 256\n",
    "n_input = 784 # Default 784\n",
    "n_classes = 10 # Number of digits 0...9\n",
    "n_samples = mnist.train.num_examples\n",
    "\n",
    "x = tf.placeholder('float', [None, n_input])\n",
    "y = tf.placeholder('float', [None, n_classes])\n",
    "\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(x, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "    }\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe save this for later 😒"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
